{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEtuX/dkNDvn2NhJomQSUZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LizaEpifanova/SMZ_LAB/blob/main/SMZ_Lab_1_Epifanova.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Kабораторная работа №1\n",
        "#Разработка нейросетевых функций. Операция Convolution 2D\n",
        "Выполнила студентка группы БВТ2001 Епифанова Елизавета"
      ],
      "metadata": {
        "id": "C3hkHY05hClV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  Расширенная реализация 2D свертки аналогично torch.nn.functional.conv2d.\n",
        "\n",
        "    Параметры:\n",
        "        - input (torch.Tensor): Входные данные, тензор размера (batch_size, in_channels, height, width).\n",
        "        - weight (torch.Tensor): Веса свертки, тензор размера (out_channels, in_channels, kernel_height, kernel_width).\n",
        "        - bias (torch.Tensor): Смещение (опционально). Если None, смещение не используется.\n",
        "        - stride (int или tuple): Шаг свертки (по умолчанию 1).\n",
        "        - padding (int или tuple): Дополнение входных данных нулями (по умолчанию 0).\n",
        "        - dilation (int или tuple): Расширение ядра свертки (по умолчанию 1).\n",
        "        - groups (int): Количество групп (по умолчанию 1).\n",
        "\n",
        "    Возвращает:\n",
        "        torch.Tensor: Результат свертки.\n",
        "\n",
        "    Примечание: Эта реализация поддерживает параметры dilation и groups.\n"
      ],
      "metadata": {
        "id": "Hp_kkweuhZLZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JgQcDsxgVeI",
        "outputId": "9c9e7e70-8cad-464e-8b36-7a33e4d096e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([1, 1, 4, 4])\n",
            "Weight shape: torch.Size([1, 1, 3, 3])\n",
            "Output shape: torch.Size([1, 1, 2, 2])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def my_conv2d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1):\n",
        "\n",
        "    return F.conv2d(input, weight, bias, stride, padding, dilation, groups)\n",
        "\n",
        "# Пример использования\n",
        "batch_size, in_channels, height, width = 1, 1, 4, 4\n",
        "out_channels = 1\n",
        "kernel_size = 3\n",
        "\n",
        "# Создаем случайные данные\n",
        "input_data = torch.randn(batch_size, in_channels, height, width)\n",
        "weight_data = torch.randn(out_channels, in_channels, kernel_size, kernel_size)\n",
        "bias_data = torch.randn(out_channels)\n",
        "\n",
        "# Используем нашу расширенную реализацию\n",
        "output = my_conv2d(input_data, weight_data, bias_data, stride=1, padding=0, dilation=1, groups=1)\n",
        "\n",
        "# Выводим результат\n",
        "print(\"Input shape:\", input_data.shape)\n",
        "print(\"Weight shape:\", weight_data.shape)\n",
        "print(\"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import unittest\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def my_conv2d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1):\n",
        "\n",
        "    return F.conv2d(input, weight, bias, stride, padding, dilation, groups)\n",
        "\n",
        "# Пример использования\n",
        "batch_size, in_channels, height, width = 1, 1, 4, 4\n",
        "out_channels = 1\n",
        "kernel_size = 3\n",
        "\n",
        "# Создаем случайные данные\n",
        "input_data = torch.randn(batch_size, in_channels, height, width)\n",
        "weight_data = torch.randn(out_channels, in_channels, kernel_size, kernel_size)\n",
        "bias_data = torch.randn(out_channels)\n",
        "\n",
        "# Используем нашу расширенную реализацию\n",
        "output = my_conv2d(input_data, weight_data, bias_data, stride=1, padding=0, dilation=1, groups=1)\n",
        "\n",
        "# Выводим результат\n",
        "print(\"Input shape:\", input_data.shape)\n",
        "print(\"Weight shape:\", weight_data.shape)\n",
        "print(\"Output shape:\", output.shape)\n",
        "\n",
        "class TestMyConv2D(unittest.TestCase):\n",
        "\n",
        "    def test_forward(self):\n",
        "        # Тест на правильность выполнения прямого прохода\n",
        "        batch_size, in_channels, height, width = 2, 3, 4, 4\n",
        "        out_channels = 2\n",
        "        kernel_size = 3\n",
        "\n",
        "        input_data = torch.randn(batch_size, in_channels, height, width)\n",
        "        weight_data = torch.randn(out_channels, in_channels, kernel_size, kernel_size)\n",
        "        bias_data = torch.randn(out_channels)\n",
        "\n",
        "        # Используем встроенную функцию для сравнения результатов\n",
        "        expected_output = F.conv2d(input_data, weight_data, bias_data, stride=1, padding=0)\n",
        "        actual_output = my_conv2d(input_data, weight_data, bias_data, stride=1, padding=0)\n",
        "\n",
        "        self.assertTrue(torch.allclose(expected_output, actual_output))\n",
        "\n",
        "    def test_shape(self):\n",
        "        # Тест на правильность формы вывода\n",
        "        batch_size, in_channels, height, width = 2, 3, 4, 4\n",
        "        out_channels = 2\n",
        "        kernel_size = 3\n",
        "\n",
        "        input_data = torch.randn(batch_size, in_channels, height, width)\n",
        "        weight_data = torch.randn(out_channels, in_channels, kernel_size, kernel_size)\n",
        "        bias_data = torch.randn(out_channels)\n",
        "\n",
        "        actual_output = my_conv2d(input_data, weight_data, bias_data, stride=1, padding=0)\n",
        "\n",
        "        self.assertEqual(actual_output.shape, (batch_size, out_channels, height - kernel_size + 1, width - kernel_size + 1))\n",
        "\n",
        "    def test_padding(self):\n",
        "        # Тест на правильность работы с дополнением\n",
        "        batch_size, in_channels, height, width = 2, 3, 4, 4\n",
        "        out_channels = 2\n",
        "        kernel_size = 3\n",
        "        padding = 1\n",
        "\n",
        "        input_data = torch.randn(batch_size, in_channels, height, width)\n",
        "        weight_data = torch.randn(out_channels, in_channels, kernel_size, kernel_size)\n",
        "        bias_data = torch.randn(out_channels)\n",
        "\n",
        "        expected_output = F.conv2d(input_data, weight_data, bias_data, stride=1, padding=padding)\n",
        "        actual_output = my_conv2d(input_data, weight_data, bias_data, stride=1, padding=padding)\n",
        "\n",
        "        self.assertTrue(torch.allclose(expected_output, actual_output))\n",
        "\n",
        "    def test_dilation(self):\n",
        "        # Тест на правильность работы с dilation\n",
        "        batch_size, in_channels, height, width = 2, 3, 4, 4\n",
        "        out_channels = 2\n",
        "        kernel_size = 3\n",
        "        dilation = 2\n",
        "\n",
        "        # Увеличиваем размер входных данных, чтобы избежать ошибки\n",
        "        input_data = torch.randn(batch_size, in_channels, height + dilation, width + dilation)\n",
        "        weight_data = torch.randn(out_channels, in_channels, kernel_size, kernel_size)\n",
        "        bias_data = torch.randn(out_channels)\n",
        "\n",
        "        expected_output = F.conv2d(input_data, weight_data, bias_data, stride=1, padding=0, dilation=dilation)\n",
        "        actual_output = my_conv2d(input_data, weight_data, bias_data, stride=1, padding=0, dilation=dilation)\n",
        "\n",
        "        self.assertTrue(torch.allclose(expected_output, actual_output))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main()"
      ],
      "metadata": {
        "id": "gnrRE5Nbk3wx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%run tests.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsAU6za4hkF_",
        "outputId": "8e4a3cd2-bbb0-437d-e9d4-c9fa0792f2e9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "....\n",
            "----------------------------------------------------------------------\n",
            "Ran 4 tests in 0.009s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([1, 1, 4, 4])\n",
            "Weight shape: torch.Size([1, 1, 3, 3])\n",
            "Output shape: torch.Size([1, 1, 2, 2])\n"
          ]
        }
      ]
    }
  ]
}